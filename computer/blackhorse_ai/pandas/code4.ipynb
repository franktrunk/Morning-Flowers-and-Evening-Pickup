{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数组组合-concat函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('mdata/concat_1.csv')\n",
    "df2 = pd.read_csv('mdata/concat_2.csv')\n",
    "df3 = pd.read_csv('mdata/concat_3.csv')\n",
    "df1\n",
    "df2\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat函数，把df对象连接起来\n",
    "pd.concat([df1,df2,df3])\n",
    "pd.concat([df1,df2,df3],axis='rows')\n",
    "pd.concat([df1,df2,df3],axis=0) # 按行拼接\n",
    "pd.concat([df1,df2,df3],axis= 1 ) # 按列拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把DataFrame和Series对象拼接到一起\n",
    "# 由于series是列数据，concat方法默认是添加行，但是series没有行所以，所以添加了新的列，缺失值用nan填充\n",
    "s1 = pd.Series(['n1','n2','n3'])\n",
    "pd.concat([df1,s1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将['n1','n2','n3','n4']作为行连接到df1之后\n",
    "# 按行拼接，参考列名；按列拼接，参考行名\n",
    "df5 = pd.DataFrame([['n1','n2','n3','n4']],columns=['A','B','C','D']) #这里得套两层，套一层识别为series\n",
    "pd.concat([df1,df5],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],axis='columns')\n",
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['new_col1'] = 'ai20'\n",
    "df1\n",
    "\n",
    "df1['new_col2'] = ['张三','李四','王五','赵六']\n",
    "df1\n",
    "\n",
    "# 还可以吧添加的列值封装为series\n",
    "df1['new_col2'] = pd.Series(['hh','aa','zz','xx'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.merge()方式  合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 一对一合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sqlite中读取数据\n",
    "conn = sqlite3.connect('mdata/chinook.db')\n",
    "tracks = pd.read_sql_query('select * from tracks;' ,conn) # 歌曲表\n",
    "tracks.head()\n",
    "\n",
    "genres = pd.read_sql_query('select * from genres;',conn)\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 为了更好的演示，连接查询，防止不相关的列干扰我们。我们从歌曲表中抽取一些数据\n",
    "tracks_subset = tracks.loc[[0,62,76,98,110,193,204,281,322,359]]\n",
    "tracks_subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过merge函数，实现tracks_subset和genres连接操作\n",
    "# 格式 dfa.merge(dfb,on='关联字段',how='连接方式')\n",
    "# 如果两个df对象关联字段一样，用on直接连接，如果不一样，用left_on = '左df字段名'，right_on = '右df字段名'\n",
    "genres.merge(tracks_subset[['TrackId','GenreId','Milliseconds']],on = 'GenreId',how = 'left')\n",
    "genres.merge(tracks_subset[['TrackId','GenreId','Milliseconds']],on = 'GenreId',how = 'right')\n",
    "genres.merge(tracks_subset[['TrackId','GenreId','Milliseconds']],on = 'GenreId',how = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果两个df的字段重名了，则suffixes=('_x','_y')会分别给左df 和 右df加后缀，以示区分\n",
    "genres.merge(tracks_subset[['TrackId','Name','GenreId','Milliseconds']],on = 'GenreId',how = 'outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 多对一合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.merge(tracks_subset) # 一对一，因为tracks_subset中只有10条数据，且歌曲分类id都是不同的\n",
    "genres.merge(tracks) # 一对多，tracks中多收歌曲可能属于一个类别\n",
    "genre_track =genres.merge(tracks[['TrackId','GenreId','Milliseconds']],on = 'GenreId', how = 'left')\n",
    "genre_track \n",
    "\n",
    "# 基于上述数据，按照歌曲类别分组，计算平均时长\n",
    "tmp_series = genre_track.groupby(['GenreId','Name'])['Milliseconds'].mean()\n",
    "tmp_series\n",
    "\n",
    "## 基于上述数据，构成日期格式\n",
    "pd.to_timedelta(tmp_series,unit='ms').dt.floor('s').sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
