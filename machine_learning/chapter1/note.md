# 机器学习定义
## 数据
### 非结构型数据
* 图片、文本、语音、棋盘等

## 监督学习
* 所有样本都有标记
* 任务类型：二分类、多分类、回归、结构预测

## 半监督学习
* 只有部分样本有标记
### 任务类型
* 转导学习：仅针对特定的未标记样本预测它们的标签，不追求构建一个泛化的模型。利用所有可用数据来提升对这些特定样本的预测。只能对训练阶段已知的未标记样本做预测，不能处理之后新来的样本
* 归纳学习：从已知的训练数据（有标签）中学习一个通用模型。模型是显式的，可以泛化到任何新样本，学习过程独立于具体的测试样本

## 无监督学习
* 所有样本都没有标记

### 任务类型
* 聚类：依相似度将数据分成若干个簇。同一簇内的样本尽可能相似，不同簇间的样本尽可能不，相似度”可以基于欧氏距离、余弦相似度等。
* 降维：将高维数据映射到低维空间，同时保留尽可能多的重要信息。可视化、去噪、加速后续模型训练、学习更紧凑、更有意义的特征表示
* 密度估计：估计数据所来自的概率分布即建模整个数据的联合概率密度。用于异常检测、数据生成等

### 聚类
* 最具代表性的是k-均值 (k-means) 算法，其中k是目标簇数，需事先指定 (算法的输入)
* 思路：数据聚成k个簇C1,…,Ck，每个样本都恰属于某一个簇，每个样本到所在簇簇中心的距离小于与其它簇中心的距离
* 优化问题：求让样本点到对应质心的距离最短
* 求解算法：随机初始化k个簇中心，重复以下两步直至收敛：1： 将每个样本分配到距其最近的簇中心；2： 更新每个簇的中心

### 降维
* 其实就是主成分分析

### 核密度估计
* 关于0中心对称的非负函数称为核函数 (kernel function)，对应的估计为核密度估计 (kernel density estimation, KDE)

### 评估
* 回归：回归任务最常用的评估指标均方损失
* 二分类： 分类任务最常用的评估指标错误率也称为 0-1 损失

### 混淆矩阵
* 只看准确率有时不够全面：类别不平衡、误分类代价差别大
* 查准率(precision)：预测的正样本中有多少是正样本
* 查全率(recall)：所有正样本中有多少被预测出来了
* 更常用的是查准率、查全率的调和平均，称为F1

### 评估 交叉熵损失
* 错误率不连续、难优化，通常采用交叉熵 (cross-entropy) 损失